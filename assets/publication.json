[
  {
      "title": "[IROS'25] FABRIC: FAbricating Bodily-Expressive Robots for Inclusive and Low-Cost Design",
      "image": "assets/publication-images/fabric.png",
      "pdf": "https://hcied.info/papers/2025IROS-Fabric_Final.pdf",
      "video": "https://youtu.be/ndf2YhFQPJ4",
      "summary": "Sign language serves individuals with hearing impairments as a crucial communication mode operating through visual-manual means. While there has been established theory and agreement about embodiment in multiple fields, only limited research has deeply engaged to lower access to the physical body for spatial perception and engagement. Embodied robots are often cost-prohibitive, and existing open-source robot fabrication packages are limited in their ability to fully address communication nuances, typically running only on predefined programs.  Reprogramming for broader bodily interactions, such as gestures in various domains (e.g., construction), is nearly impossible unless expertise precedes. We introduce FABRIC, an end-to-end toolkit for fabricating and programming bodily language for unique human-robot interactions. The toolkit includes a fully 3D-printable robot, designed for consumer-grade FDM machinery, that learns from demonstration (LfD) to capture and translate users' bodily expressions through its upper torso (arms and hands) movements. A visual programming interface enables appending or sequencing demonstrations from various sources, i.e., videos, cameras, and expandable word/phrase/sentence libraries."
    },
    {
      "title": "[IMWUT/UBICOMP'23] E3D: Harvesting Energy from Everyday Kinetic Interactions Using 3D Printed Attachment Mechanisms",
      "image": "assets/publication-images/e3d.jpg",
      "pdf": "https://dl.acm.org/doi/pdf/10.1145/3610897",
      "video": "https://youtu.be/rQ4pxmuiLG8",
      "summary": "The increase of distributed embedded systems has enabled pervasive sensing, actuation, and information displays across buildings and surrounding environments, yet also entreats huge cost expenditure for energy and human labor for maintenance. Our daily interactions, from opening a window to closing a drawer to twisting a doorknob, are great potential sources of energy but are often neglected. Existing commercial devices to harvest energy from these ambient sources are unaffordable, and DIY solutions are left with inaccessibility for non-experts preventing fully imbuing daily innovations in end-users. We present E3D, an end-to-end fabrication toolkit to customize self-powered smart devices at low cost. We contribute to a taxonomy of everyday kinetic activities that are potential sources of energy, a library of parametric mechanisms to harvest energy from manual operations of kinetic objects, and a holistic design system for end-user developers to capture design requirements by demonstrations then customize augmentation devices to harvest energy that meets unique lifestyle."
    },
    {
      "title": "[CHI'22]Mobiot: Augmenting Everyday Objects into Moving IoT Devices Using 3D Printed Attachments Generated by Demonstration",
      "image": "assets/publication-images/mobiot.jpg",
      "pdf": "https://hcied.info/papers/mobiot-CHI22.pdf",
      "video": "https://youtu.be/uX7m3bPknnI",
      "summary": "Recent advancements in personal fabrication have brought novices closer to a reality, where they can automate routine tasks with mobilized everyday objects. However, the overall process remains challenging- from capturing design requirements and motion planning to authoring them to creating 3D models of mechanical parts to programming electronics, as it demands expertise. We introduce Mobiot, an end-user toolkit to help non-experts capture the design and motion requirements of legacy objects by demonstration. It then automatically generates 3D printable attachments, programs to operate assembled modules, a list of off-the-shelf electronics, and assembly tutorials. The authoring feature further assists users to fine-tune as well as to reuse existing motion libraries and 3D printed mechanisms to adapt to other real-world objects with different motions. We validate Mobiot through application examples with 8 everyday objects with various motions applied, and through technical evaluation to measure the accuracy of motion reconstruction."
    }
  ]
  